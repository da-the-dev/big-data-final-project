log4j:WARN No appenders could be found for logger (org.apache.hadoop.util.Shell).
log4j:WARN Please initialize the log4j system properly.
log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.
Connecting to jdbc:hive2://hadoop-03.uni.innopolis.ru:10001
Connected to: Apache Hive (version 3.1.3)
Driver: Hive JDBC (version 2.3.9)
Transaction isolation: TRANSACTION_REPEATABLE_READ
INFO  : Compiling command(queryId=hive_20250509122835_4c7b93ff-b534-4d8f-ada7-2fa2df4b8c3b): DROP DATABASE IF EXISTS team26_projectdb CASCADE
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20250509122835_4c7b93ff-b534-4d8f-ada7-2fa2df4b8c3b : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0


INFO  : Completed compiling command(queryId=hive_20250509122835_4c7b93ff-b534-4d8f-ada7-2fa2df4b8c3b); Time taken: 0.558 seconds
INFO  : Executing command(queryId=hive_20250509122835_4c7b93ff-b534-4d8f-ada7-2fa2df4b8c3b): DROP DATABASE IF EXISTS team26_projectdb CASCADE
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20250509122835_4c7b93ff-b534-4d8f-ada7-2fa2df4b8c3b); Time taken: 2.099 seconds
INFO  : OK
No rows affected (3.16 seconds)
INFO  : Compiling command(queryId=hive_20250509122838_fab4cc5b-6bed-49c7-9834-07ec05d5d3b0): CREATE DATABASE team26_projectdb LOCATION "project/hive/warehouse"
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20250509122838_fab4cc5b-6bed-49c7-9834-07ec05d5d3b0 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0


INFO  : Completed compiling command(queryId=hive_20250509122838_fab4cc5b-6bed-49c7-9834-07ec05d5d3b0); Time taken: 0.025 seconds
INFO  : Executing command(queryId=hive_20250509122838_fab4cc5b-6bed-49c7-9834-07ec05d5d3b0): CREATE DATABASE team26_projectdb LOCATION "project/hive/warehouse"
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20250509122838_fab4cc5b-6bed-49c7-9834-07ec05d5d3b0); Time taken: 0.014 seconds
INFO  : OK
No rows affected (0.062 seconds)
INFO  : Compiling command(queryId=hive_20250509122838_1356ff72-559b-4006-beba-2dae17ee5219): USE team26_projectdb
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20250509122838_1356ff72-559b-4006-beba-2dae17ee5219 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0


INFO  : Completed compiling command(queryId=hive_20250509122838_1356ff72-559b-4006-beba-2dae17ee5219); Time taken: 0.014 seconds
INFO  : Executing command(queryId=hive_20250509122838_1356ff72-559b-4006-beba-2dae17ee5219): USE team26_projectdb
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20250509122838_1356ff72-559b-4006-beba-2dae17ee5219); Time taken: 0.006 seconds
INFO  : OK
No rows affected (0.027 seconds)
No rows affected (0.005 seconds)
No rows affected (0.003 seconds)
No rows affected (0.004 seconds)
INFO  : Compiling command(queryId=hive_20250509122838_770d1d07-4ffb-4304-96de-c5c7135d9cf8): CREATE EXTERNAL TABLE traffic (
id STRING,
severity INT,
start_lat DOUBLE,
start_lng DOUBLE,
start_time BIGINT,
end_time BIGINT,
distance DOUBLE,
delay_from_typical_traffic DOUBLE,
delay_from_free_flow_speed DOUBLE,
congestion_speed STRING,
description STRING,
street STRING,
city STRING,
county STRING,
state STRING,
country STRING,
zip_code STRING,
local_time_zone STRING,
weather_station_airport_code STRING,
weather_time_stamp BIGINT,
temperature DOUBLE,
wind_chill DOUBLE,
humidity DOUBLE,
pressure DOUBLE,
visibility DOUBLE,
wind_dir STRING,
wind_speed DOUBLE,
precipitation DOUBLE,
weather_event STRING,
weather_conditions STRING
)
STORED AS PARQUET
LOCATION 'project/warehouse/traffic'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20250509122838_770d1d07-4ffb-4304-96de-c5c7135d9cf8 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0
      Create Table Operator:
        Create Table
          columns: id string, severity int, start_lat double, start_lng double, start_time bigint, end_time bigint, distance double, delay_from_typical_traffic double, delay_from_free_flow_speed double, congestion_speed string, description string, street string, city string, county string, state string, country string, zip_code string, local_time_zone string, weather_station_airport_code string, weather_time_stamp bigint, temperature double, wind_chill double, humidity double, pressure double, visibility double, wind_dir string, wind_speed double, precipitation double, weather_event string, weather_conditions string
          input format: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
          location: project/warehouse/traffic
          output format: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
          serde name: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
          name: team26_projectdb.traffic
          isExternal: true


INFO  : Completed compiling command(queryId=hive_20250509122838_770d1d07-4ffb-4304-96de-c5c7135d9cf8); Time taken: 0.048 seconds
INFO  : Executing command(queryId=hive_20250509122838_770d1d07-4ffb-4304-96de-c5c7135d9cf8): CREATE EXTERNAL TABLE traffic (
id STRING,
severity INT,
start_lat DOUBLE,
start_lng DOUBLE,
start_time BIGINT,
end_time BIGINT,
distance DOUBLE,
delay_from_typical_traffic DOUBLE,
delay_from_free_flow_speed DOUBLE,
congestion_speed STRING,
description STRING,
street STRING,
city STRING,
county STRING,
state STRING,
country STRING,
zip_code STRING,
local_time_zone STRING,
weather_station_airport_code STRING,
weather_time_stamp BIGINT,
temperature DOUBLE,
wind_chill DOUBLE,
humidity DOUBLE,
pressure DOUBLE,
visibility DOUBLE,
wind_dir STRING,
wind_speed DOUBLE,
precipitation DOUBLE,
weather_event STRING,
weather_conditions STRING
)
STORED AS PARQUET
LOCATION 'project/warehouse/traffic'
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20250509122838_770d1d07-4ffb-4304-96de-c5c7135d9cf8); Time taken: 0.053 seconds
INFO  : OK
No rows affected (0.145 seconds)
INFO  : Compiling command(queryId=hive_20250509122838_e2ac0eef-e564-4ea5-a5ea-186b43a450d9): CREATE TABLE states_list
STORED AS ORC AS
SELECT DISTINCT state
FROM traffic
WHERE state IS NOT NULL AND state != ''
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:state, type:string, comment:null)], properties:null)
INFO  : EXPLAIN output for queryid hive_20250509122838_e2ac0eef-e564-4ea5-a5ea-186b43a450d9 : STAGE DEPENDENCIES:
  Stage-1 is a root stage [MAPRED]
  Stage-2 depends on stages: Stage-1 [DEPENDENCY_COLLECTION]
  Stage-4 depends on stages: Stage-2, Stage-0 [DDL]
  Stage-3 depends on stages: Stage-4 [STATS]
  Stage-0 depends on stages: Stage-1 [MOVE]

STAGE PLANS:
  Stage: Stage-1
    Tez
      DagId: hive_20250509122838_e2ac0eef-e564-4ea5-a5ea-186b43a450d9:12770
      Edges:
        Reducer 2 <- Map 1 (SIMPLE_EDGE)
      DagName: hive_20250509122838_e2ac0eef-e564-4ea5-a5ea-186b43a450d9:12770
      Vertices:
        Map 1 
            Map Operator Tree:
                TableScan
                  alias: traffic
                  Statistics: Num rows: 16159796 Data size: 27600932864 Basic stats: COMPLETE Column stats: NONE
                  GatherStats: false
                  Filter Operator
                    isSamplingPred: false
                    predicate: (state <> '') (type: boolean)
                    Statistics: Num rows: 16159796 Data size: 27600932864 Basic stats: COMPLETE Column stats: NONE
                    Group By Operator
                      keys: state (type: string)
                      mode: hash
                      outputColumnNames: _col0
                      Statistics: Num rows: 16159796 Data size: 27600932864 Basic stats: COMPLETE Column stats: NONE
                      Reduce Output Operator
                        key expressions: _col0 (type: string)
                        null sort order: a
                        sort order: +
                        Map-reduce partition columns: _col0 (type: string)
                        Statistics: Num rows: 16159796 Data size: 27600932864 Basic stats: COMPLETE Column stats: NONE
                        tag: -1
                        auto parallelism: true
            Execution mode: vectorized
            Path -> Alias:
              hdfs://hadoop-02.uni.innopolis.ru:8020/user/team26/project/warehouse/traffic [traffic]
            Path -> Partition:
              hdfs://hadoop-02.uni.innopolis.ru:8020/user/team26/project/warehouse/traffic 
                Partition
                  base file name: traffic
                  input format: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
                  output format: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
                  properties:
                    EXTERNAL TRUE
                    bucket_count -1
                    bucketing_version 2
                    column.name.delimiter ,
                    columns id,severity,start_lat,start_lng,start_time,end_time,distance,delay_from_typical_traffic,delay_from_free_flow_speed,congestion_speed,description,street,city,county,state,country,zip_code,local_time_zone,weather_station_airport_code,weather_time_stamp,temperature,wind_chill,humidity,pressure,visibility,wind_dir,wind_speed,precipitation,weather_event,weather_conditions
                    columns.comments 
                    columns.types string:int:double:double:bigint:bigint:double:double:double:string:string:string:string:string:string:string:string:string:string:bigint:double:double:double:double:double:string:double:double:string:string
                    file.inputformat org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
                    file.outputformat org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
                    location hdfs://hadoop-02.uni.innopolis.ru:8020/user/team26/project/warehouse/traffic
                    name team26_projectdb.traffic
                    numFiles 4
                    serialization.ddl struct traffic { string id, i32 severity, double start_lat, double start_lng, i64 start_time, i64 end_time, double distance, double delay_from_typical_traffic, double delay_from_free_flow_speed, string congestion_speed, string description, string street, string city, string county, string state, string country, string zip_code, string local_time_zone, string weather_station_airport_code, i64 weather_time_stamp, double temperature, double wind_chill, double humidity, double pressure, double visibility, string wind_dir, double wind_speed, double precipitation, string weather_event, string weather_conditions}
                    serialization.format 1
                    serialization.lib org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
                    totalSize 2760093093
                    transient_lastDdlTime 1746782918
                  serde: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
                
                    input format: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
                    output format: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
                    properties:
                      EXTERNAL TRUE
                      bucket_count -1
                      bucketing_version 2
                      column.name.delimiter ,
                      columns id,severity,start_lat,start_lng,start_time,end_time,distance,delay_from_typical_traffic,delay_from_free_flow_speed,congestion_speed,description,street,city,county,state,country,zip_code,local_time_zone,weather_station_airport_code,weather_time_stamp,temperature,wind_chill,humidity,pressure,visibility,wind_dir,wind_speed,precipitation,weather_event,weather_conditions
                      columns.comments 
                      columns.types string:int:double:double:bigint:bigint:double:double:double:string:string:string:string:string:string:string:string:string:string:bigint:double:double:double:double:double:string:double:double:string:string
                      file.inputformat org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
                      file.outputformat org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
                      location hdfs://hadoop-02.uni.innopolis.ru:8020/user/team26/project/warehouse/traffic
                      name team26_projectdb.traffic
                      numFiles 4
                      serialization.ddl struct traffic { string id, i32 severity, double start_lat, double start_lng, i64 start_time, i64 end_time, double distance, double delay_from_typical_traffic, double delay_from_free_flow_speed, string congestion_speed, string description, string street, string city, string county, string state, string country, string zip_code, string local_time_zone, string weather_station_airport_code, i64 weather_time_stamp, double temperature, double wind_chill, double humidity, double pressure, double visibility, string wind_dir, double wind_speed, double precipitation, string weather_event, string weather_conditions}
                      serialization.format 1
                      serialization.lib org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
                      totalSize 2760093093
                      transient_lastDdlTime 1746782918
                    serde: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
                    name: team26_projectdb.traffic
                  name: team26_projectdb.traffic
            Truncated Path -> Alias:
              hdfs://hadoop-02.uni.innopolis.ru:8020/user/team26/project/warehouse/traffic [traffic]
        Reducer 2 
            Execution mode: vectorized
            Needs Tagging: false
            Reduce Operator Tree:
              Group By Operator
                keys: KEY._col0 (type: string)
                mode: mergepartial
                outputColumnNames: _col0
                Statistics: Num rows: 8079898 Data size: 13800466432 Basic stats: COMPLETE Column stats: NONE
                File Output Operator
                  compressed: false
                  GlobalTableId: 1
                  directory: hdfs://hadoop-02.uni.innopolis.ru:8020/user/team26/project/hive/warehouse/.hive-staging_hive_2025-05-09_12-28-38_910_2128579683097501046-9881/-ext-10002
                  NumFilesPerFileSink: 1
                  Statistics: Num rows: 8079898 Data size: 13800466432 Basic stats: COMPLETE Column stats: NONE
                  Stats Publishing Key Prefix: hdfs://hadoop-02.uni.innopolis.ru:8020/user/team26/project/hive/warehouse/.hive-staging_hive_2025-05-09_12-28-38_910_2128579683097501046-9881/-ext-10002/
                  table:
                      input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
                      output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
                      properties:
                        columns state
                        columns.types string
                        name team26_projectdb.states_list
                        serialization.format 1
                        serialization.lib org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      serde: org.apache.hadoop.hive.ql.io.orc.OrcSerde
                      name: team26_projectdb.states_list
                  TotalFiles: 1
                  GatherStats: true
                  MultiFileSpray: false

  Stage: Stage-2
    Dependency Collection

  Stage: Stage-4
      Create Table Operator:
        Create Table
          columns: state string
          input format: org.apache.hadoop.hive.ql.io.orc.OrcInputFormat
          output format: org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat
          serde name: org.apache.hadoop.hive.ql.io.orc.OrcSerde
          name: team26_projectdb.states_list

  Stage: Stage-3
    Stats Work
      Basic Stats Work:
          Stats Aggregation Key Prefix: hdfs://hadoop-02.uni.innopolis.ru:8020/user/team26/project/hive/warehouse/.hive-staging_hive_2025-05-09_12-28-38_910_2128579683097501046-9881/-ext-10002/

  Stage: Stage-0
    Move Operator
      files:
          hdfs directory: true
          source: hdfs://hadoop-02.uni.innopolis.ru:8020/user/team26/project/hive/warehouse/.hive-staging_hive_2025-05-09_12-28-38_910_2128579683097501046-9881/-ext-10002
          destination: hdfs://hadoop-02.uni.innopolis.ru:8020/user/team26/project/hive/warehouse/states_list


INFO  : Completed compiling command(queryId=hive_20250509122838_e2ac0eef-e564-4ea5-a5ea-186b43a450d9); Time taken: 0.21 seconds
INFO  : Executing command(queryId=hive_20250509122838_e2ac0eef-e564-4ea5-a5ea-186b43a450d9): CREATE TABLE states_list
STORED AS ORC AS
SELECT DISTINCT state
FROM traffic
WHERE state IS NOT NULL AND state != ''
INFO  : Query ID = hive_20250509122838_e2ac0eef-e564-4ea5-a5ea-186b43a450d9
INFO  : Total jobs = 1
INFO  : Launching Job 1 out of 1
INFO  : Starting task [Stage-1:MAPRED] in serial mode
INFO  : Subscribed to counters: [] for queryId: hive_20250509122838_e2ac0eef-e564-4ea5-a5ea-186b43a450d9
INFO  : Tez session hasn't been created yet. Opening session
INFO  : Dag name: CREATE TABLE states_list
STORED AS ORC ...'' (Stage-1)
INFO  : Status: Running (Executing on YARN cluster with App id application_1745788519616_12233)

[2K----------------------------------------------------------------------------------------------
[2K[36;1m        VERTICES      MODE        STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED  
[22;0m[2K----------------------------------------------------------------------------------------------
[2KMap 1            container        INITED     53          0        0       53       0       0  
Reducer 2        container        INITED    108          0        0      108       0       0  
[2K----------------------------------------------------------------------------------------------
[2K[31;1mVERTICES: 00/02  [>>--------------------------] 0%    ELAPSED TIME: 2.27 s     
[22;0m[2K----------------------------------------------------------------------------------------------
[8A[2K----------------------------------------------------------------------------------------------
[2K[36;1m        VERTICES      MODE        STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED  
[22;0m[2K----------------------------------------------------------------------------------------------
[2KMap 1            container       RUNNING     53          0       25       28       0       0  
Reducer 2        container        INITED    108          0        0      108       0       0  
[2K----------------------------------------------------------------------------------------------
[2K[31;1mVERTICES: 00/02  [>>--------------------------] 0%    ELAPSED TIME: 7.27 s     
[22;0m[2K----------------------------------------------------------------------------------------------
[8A[2K----------------------------------------------------------------------------------------------
[2K[36;1m        VERTICES      MODE        STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED  
[22;0m[2K----------------------------------------------------------------------------------------------
[2KMap 1 .........  container       RUNNING     53         48        5        0       0       0  
Reducer 2        container       RUNNING    108          0       20       88       0       0  
[2K----------------------------------------------------------------------------------------------
[2K[31;1mVERTICES: 00/02  [=======>>-------------------] 29%   ELAPSED TIME: 12.28 s    
[22;0m[2K----------------------------------------------------------------------------------------------
[8A[2K----------------------------------------------------------------------------------------------
[2K[36;1m        VERTICES      MODE        STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED  
[22;0m[2K----------------------------------------------------------------------------------------------
[2KMap 1 .......... container     SUCCEEDED     53         53        0        0       0       0  
Reducer 2 ...    container       RUNNING    108         55       29       24       0       0  
[2K----------------------------------------------------------------------------------------------
[2K[31;1mVERTICES: 01/02  [=================>>---------] 67%   ELAPSED TIME: 17.28 s    
[22;0m[2K----------------------------------------------------------------------------------------------
[8A[2K----------------------------------------------------------------------------------------------
[2K[36;1m        VERTICES      MODE        STATUS  TOTAL  COMPLETED  RUNNING  PENDING  FAILED  KILLED  
[22;0m[2K----------------------------------------------------------------------------------------------
INFO  : Starting task [Stage-2:DEPENDENCY_COLLECTION] in serial mode
INFO  : Starting task [Stage-0:MOVE] in serial mode
[2KMap 1 .......... container     SUCCEEDED     53         53        0        0       0       0  
Reducer 2 ...... container     SUCCEEDED    108        108        0        0       0       0  
INFO  : Moving data to directory hdfs://hadoop-02.uni.innopolis.ru:8020/user/team26/project/hive/warehouse/states_list from hdfs://hadoop-02.uni.innopolis.ru:8020/user/team26/project/hive/warehouse/.hive-staging_hive_2025-05-09_12-28-38_910_2128579683097501046-9881/-ext-10002
INFO  : Starting task [Stage-4:DDL] in serial mode
INFO  : Starting task [Stage-3:STATS] in serial mode
INFO  : Completed executing command(queryId=hive_20250509122838_e2ac0eef-e564-4ea5-a5ea-186b43a450d9); Time taken: 169.317 seconds
INFO  : OK
[2K----------------------------------------------------------------------------------------------
[2K[31;1mVERTICES: 02/02  [==========================>>] 100%  ELAPSED TIME: 19.22 s    
[22;0m[2K----------------------------------------------------------------------------------------------
No rows affected (169.564 seconds)
INFO  : Compiling command(queryId=hive_20250509123128_6a9ebe1c-5b4b-45f9-8db0-5630ea5dba76): CREATE EXTERNAL TABLE traffic_partitioned (
id STRING,
severity INT,
start_lat DOUBLE,
start_lng DOUBLE,
start_time TIMESTAMP,
end_time TIMESTAMP,
distance DOUBLE,
delay_from_typical_traffic DOUBLE,
delay_from_free_flow_speed DOUBLE,
congestion_speed STRING,
description STRING,
street STRING,
city STRING,
county STRING,
country STRING,
zip_code STRING,
local_time_zone STRING,
weather_station_airport_code STRING,
weather_time_stamp TIMESTAMP,
temperature DOUBLE,
wind_chill DOUBLE,
humidity DOUBLE,
pressure DOUBLE,
visibility DOUBLE,
wind_dir STRING,
wind_speed DOUBLE,
precipitation DOUBLE,
weather_event STRING,
weather_conditions STRING
)
PARTITIONED BY (state STRING)
CLUSTERED BY (city) INTO 4 BUCKETS
STORED AS PARQUET
LOCATION 'project/hive/warehouse/traffic_partitioned'
INFO  : Semantic Analysis Completed (retrial = false)
INFO  : Returning Hive schema: Schema(fieldSchemas:null, properties:null)
INFO  : EXPLAIN output for queryid hive_20250509123128_6a9ebe1c-5b4b-45f9-8db0-5630ea5dba76 : STAGE DEPENDENCIES:
  Stage-0 is a root stage [DDL]

STAGE PLANS:
  Stage: Stage-0
      Create Table Operator:
        Create Table
          bucket columns: city
          columns: id string, severity int, start_lat double, start_lng double, start_time timestamp, end_time timestamp, distance double, delay_from_typical_traffic double, delay_from_free_flow_speed double, congestion_speed string, description string, street string, city string, county string, country string, zip_code string, local_time_zone string, weather_station_airport_code string, weather_time_stamp timestamp, temperature double, wind_chill double, humidity double, pressure double, visibility double, wind_dir string, wind_speed double, precipitation double, weather_event string, weather_conditions string
          input format: org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat
          location: project/hive/warehouse/traffic_partitioned
          # buckets: 4
          output format: org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat
          partition columns: state string
          serde name: org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe
          name: team26_projectdb.traffic_partitioned
          isExternal: true


INFO  : Completed compiling command(queryId=hive_20250509123128_6a9ebe1c-5b4b-45f9-8db0-5630ea5dba76); Time taken: 0.043 seconds
INFO  : Executing command(queryId=hive_20250509123128_6a9ebe1c-5b4b-45f9-8db0-5630ea5dba76): CREATE EXTERNAL TABLE traffic_partitioned (
id STRING,
severity INT,
start_lat DOUBLE,
start_lng DOUBLE,
start_time TIMESTAMP,
end_time TIMESTAMP,
distance DOUBLE,
delay_from_typical_traffic DOUBLE,
delay_from_free_flow_speed DOUBLE,
congestion_speed STRING,
description STRING,
street STRING,
city STRING,
county STRING,
country STRING,
zip_code STRING,
local_time_zone STRING,
weather_station_airport_code STRING,
weather_time_stamp TIMESTAMP,
temperature DOUBLE,
wind_chill DOUBLE,
humidity DOUBLE,
pressure DOUBLE,
visibility DOUBLE,
wind_dir STRING,
wind_speed DOUBLE,
precipitation DOUBLE,
weather_event STRING,
weather_conditions STRING
)
PARTITIONED BY (state STRING)
CLUSTERED BY (city) INTO 4 BUCKETS
STORED AS PARQUET
LOCATION 'project/hive/warehouse/traffic_partitioned'
INFO  : Starting task [Stage-0:DDL] in serial mode
INFO  : Completed executing command(queryId=hive_20250509123128_6a9ebe1c-5b4b-45f9-8db0-5630ea5dba76); Time taken: 0.064 seconds
INFO  : OK
No rows affected (0.148 seconds)
Closing: 0: jdbc:hive2://hadoop-03.uni.innopolis.ru:10001
